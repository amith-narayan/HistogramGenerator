{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0961bf5e-b328-4e59-8f07-9b0b9a9d09e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df9dfc46-9697-447b-851c-f5457b6c6be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCUDA available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.cuda.is_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCUDA current: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cvmfs/icecube.opensciencegrid.org/users/jupyterhub/RHEL_9/ML-py3-v4.4.2/lib/python3.12/site-packages/torch/cuda/__init__.py:1069\u001b[39m, in \u001b[36mcurrent_device\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcurrent_device\u001b[39m() -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   1068\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1069\u001b[39m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1070\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch._C._cuda_getDevice()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cvmfs/icecube.opensciencegrid.org/users/jupyterhub/RHEL_9/ML-py3-v4.4.2/lib/python3.12/site-packages/torch/cuda/__init__.py:410\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    406\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m     )\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[32m    414\u001b[39m _tls.is_initializing = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "print(f'CUDA current: {torch.cuda.current_device()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ccbee6-1b79-4329-905d-af5a33ff2193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataGenerator():\n",
    "    def __init__(self, batchsize, bins):\n",
    "        self.batchsize=batchsize\n",
    "        self.bins=bins\n",
    "    \n",
    "    def datagen(self):\n",
    "        histograms = np.zeros((self.batchsize, 30), dtype=np.int64)\n",
    "        means = np.zeros(self.batchsize)\n",
    "        sigmas = np.zeros(self.batchsize)\n",
    "        total_counts = np.zeros(self.batchsize)\n",
    "        for i in range(self.batchsize):\n",
    "            nsamples = np.random.randint(0,10000)\n",
    "            mu = np.random.uniform(0.2,0.4)\n",
    "            sigma = np.random.uniform(0.1, 0.3)\n",
    "\n",
    "            samples = np.random.normal(mu, sigma, nsamples)\n",
    "\n",
    "            hist,_ = np.histogram(samples, bins=self.bins, range=(0,1))\n",
    "            histograms[i,:] = hist\n",
    "            means[i] = mu\n",
    "            sigmas[i] = sigma\n",
    "            total_counts[i] = hist.sum()\n",
    "\n",
    "        return histograms, means, sigmas, total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa2e5b5-cf7d-4701-9584-85363fa84e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataGenerator(2500000,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e71f2ed-f317-43a1-9971-050bf5d3ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, means, sigmas, counts = data.datagen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dabf1e3-1b7a-4b02-af61-2c4eb567b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.array(means)\n",
    "sigmas = np.array(sigmas)\n",
    "counts = np.array(counts)\n",
    "conds = np.column_stack([means, sigmas, counts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93126e78-d4b8-43ca-af87-3eb7bfc0164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_train, hist_test, conds_train, conds_test = train_test_split(hist,conds, test_size=0.2, random_state=42)\n",
    "\n",
    "hist_test = torch.tensor(hist_test, dtype=torch.float32)\n",
    "hist_test = hist_test/hist_test.max().item()\n",
    "hist_train = torch.tensor(hist_train, dtype=torch.float32)\n",
    "hist_train = hist_train/hist_train.max().item()\n",
    "conds_test = torch.tensor(conds_test, dtype=torch.float32)\n",
    "conds_train = torch.tensor(conds_train, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020904a2-3521-4b10-8d47-2887ea515cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, cond_dim: int, hidden_dim: int, input_dim=30):\n",
    "        super().__init__()\n",
    "        self.input_dim=input_dim\n",
    "        self.cond_dim=cond_dim\n",
    "        self.total_dim=self.input_dim + self.cond_dim\n",
    "        self.Mu = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.total_dim,hidden_dim),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "\n",
    "            torch.nn.Linear(hidden_dim,hidden_dim * 2),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim * 2),\n",
    "\n",
    "            torch.nn.Linear(hidden_dim * 2, hidden_dim * 4),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim * 4),\n",
    "\n",
    "            torch.nn.Linear(hidden_dim * 4, hidden_dim * 2),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim * 2),\n",
    "\n",
    "            torch.nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "\n",
    "            torch.nn.Linear(hidden_dim, 32),\n",
    "            torch.nn.Softplus()\n",
    "        )\n",
    "\n",
    "        self.Sigma = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.total_dim,hidden_dim),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "\n",
    "            torch.nn.Linear(hidden_dim,hidden_dim * 2),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim * 2),\n",
    "\n",
    "            torch.nn.Linear(hidden_dim * 2, hidden_dim * 4),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim * 4),\n",
    "\n",
    "            torch.nn.Linear(hidden_dim * 4, hidden_dim * 2),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim * 2),\n",
    "\n",
    "            torch.nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.BatchNorm1d(hidden_dim),\n",
    "\n",
    "            torch.nn.Linear(hidden_dim, 32),\n",
    "            torch.nn.Softplus()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input_vec, cond_vec):\n",
    "\n",
    "        x = torch.cat([input_vec, cond_vec], dim=1)\n",
    "\n",
    "        mu = self.Mu(x)\n",
    "        sigma = self.Sigma(x)\n",
    "\n",
    "        return mu, sigma  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3507046e-10d7-417d-be9c-6d234f794ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-v4.4.2: ML Libaries/Software - v1.16.0",
   "language": "shell",
   "name": "ml_py3-v4.4.2_v1.16.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
